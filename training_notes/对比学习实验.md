## 测试全连接层输出不同维数和batch对对比学习效果的影响

训练SimCSE后放入全连接层分类结果:

### batch=16,out_units=128,无正则化

test_loss: 2.30486798286438
test_accuracy: 0.40784314274787903
test_precision: 0.75
test_recall: 0.1764705926179886
test_f1score: 0.28571426061949806

### batch=16,out_units=512,l2正则化

test_loss: 1.9399033784866333
test_accuracy: 0.5411764979362488
test_precision: 0.7669903039932251
test_recall: 0.30980393290519714
test_f1score: 0.4413407547474297

batch=16,out_units=256,l2正则化

## 测试融合原模型与对比学习增强向量后的分类效果

方法1：直接拼接

512+512，batch=16

epoch=100

test_loss: 3.7482433319091797
test_accuracy: 0.729411780834198
test_precision: 0.8148148059844971
test_recall: 0.6039215922355652
test_f1score: 0.6936936571726129

epoch=120

test_loss: 3.5759084224700928
test_accuracy: 0.7372549176216125
test_precision: 0.8041236996650696
test_recall: 0.6117647290229797
test_f1score: 0.6948774670593308

epoch=142(val_loss难下降)

test_loss: 3.4523634910583496
test_accuracy: 0.7490196228027344
test_precision: 0.8059701323509216
test_recall: 0.6352941393852234
test_f1score: 0.7105262735181402

256+256，batch=16，simCSE已经训练至极小的loss，

epoch=98

test_loss: 3.750908613204956
test_accuracy: 0.7803921699523926
test_precision: 0.8173912763595581
test_recall: 0.7372549176216125
test_f1score: 0.7752576781614732

epoch=120

test_loss: 3.6330454349517822
test_accuracy: 0.7803921699523926
test_precision: 0.818965494632721
test_recall: 0.7450980544090271
test_f1score: 0.7802874225135568

原模型

test_loss: 4.073619365692139
test_accuracy: 0.7882353067398071
test_precision: 0.8101266026496887
test_recall: 0.7529411911964417
test_f1score: 0.7804877723104581

应当尝试有监督的对比学习

采用测试集作为验证，得到的最佳结果

test_loss: 3.388040065765381
test_accuracy: 0.7960784435272217
test_precision: 0.832617998123169
test_recall: 0.7607843279838562
test_f1score: 0.7950819125046968

与之对比，不含对比学习的模型结果

test_loss: 3.873246431350708
test_accuracy: 0.7686274647712708
test_precision: 0.7991452813148499
test_recall: 0.7333333492279053
test_f1score: 0.7648261264399261

尝试了focal loss后，发现效果不如普通的交叉熵
